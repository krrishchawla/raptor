{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912cd8c6-d405-4dfe-8897-46108e6a6af7",
   "metadata": {},
   "source": [
    "# RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "631b09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: An OpenAI API key must be set here for application initialization, even if not in use.\n",
    "# If you're not utilizing OpenAI models, assign a placeholder string (e.g., \"not_used\").\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d7d995-7beb-40b5-9a44-afd350b7d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('finQA/output_summary_metadata.json', 'r') as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d51ebd-5597-4fdd-8c37-32636395081b",
   "metadata": {},
   "source": [
    "1) **Building**: RAPTOR recursively embeds, clusters, and summarizes chunks of text to construct a tree with varying levels of summarization from the bottom up. You can create a tree from the text in 'sample.txt' using `RA.add_documents(text)`.\n",
    "\n",
    "2) **Querying**: At inference time, the RAPTOR model retrieves information from this tree, integrating data across lengthy documents at different abstraction levels. You can perform queries on the tree with `RA.answer_question`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f58830-9004-48a4-b50e-61a855511d24",
   "metadata": {},
   "source": [
    "### Building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3753fcf9-0a8e-4ab3-bf3a-6be38ef6cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krrishchawla/Desktop/CS/raptor/raptor/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-03 12:41:34,385 - Loading faiss.\n",
      "2024-06-03 12:41:34,426 - Successfully loaded faiss.\n"
     ]
    }
   ],
   "source": [
    "from raptor import RetrievalAugmentation, RetrievalAugmentationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2365702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raptor import ClusterTreeBuilder, ClusterTreeConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9472871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raptor.QAModels import GPT4oQAModel\n",
    "from raptor.SummarizationModels import GPT4oSummarizationModel\n",
    "\n",
    "custom_qa = GPT4oQAModel()\n",
    "custom_summarizer = GPT4oSummarizationModel()\n",
    "\n",
    "custom_config = RetrievalAugmentationConfig(\n",
    "    json_data=json_data,\n",
    "    summarization_model=custom_summarizer,\n",
    "    qa_model=custom_qa\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4253ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc = ClusterTreeConfig(json_data=json_data,\n",
    "    summarization_model=custom_summarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctb = ClusterTreeBuilder(config=ctc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558740a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctb.build_from_json(ctb.json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e843edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RA = RetrievalAugmentation(config=custom_config)\n",
    "\n",
    "# construct the tree\n",
    "RA.add_documents(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd34f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "RA.tree.layer_to_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f219d60a-1f0b-4cee-89eb-2ae026f13e63",
   "metadata": {},
   "source": [
    "### Querying from the tree\n",
    "\n",
    "```python\n",
    "question = # any question\n",
    "RA.answer_question(question)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4037c5-ad5a-424b-80e4-a67b8e00773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Apple?\"\n",
    "answer = RA.answer_question(question=question)\n",
    "\n",
    "print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5be7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tree by calling RA.save(\"path/to/save\")\n",
    "SAVE_PATH = \"finQA/GPT4o_full_metadata\"\n",
    "# RA.save(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e845de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 22:09:53,428 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 500\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT4oSummarizationModel object at 0x7fa184c2e850>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fa191738c40>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2024-06-02 22:09:53,429 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 500\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT4oSummarizationModel object at 0x7fa184c2e850>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fa191738c40>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2024-06-02 22:09:53,431 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: OpenAI\n",
      "            Embedding Model: <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fa1e6178dc0>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "2024-06-02 22:09:53,432 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 500\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT4oSummarizationModel object at 0x7fa184c2e850>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fa191738c40>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: OpenAI\n",
      "            Embedding Model: <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fa1e6178dc0>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <raptor.QAModels.GPT4oQAModel object at 0x7fa1d6332df0>\n",
      "            Tree Builder Type: cluster\n",
      "        \n",
      "2024-06-02 22:09:53,555 - Using collapsed_tree\n",
      "2024-06-02 22:09:54,229 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:09:58,025 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Apple Inc.'s net revenue for the year 2012 was $156.5 billion. This figure represents a significant increase from the previous years, with net sales of $108.2 billion in 2011 and $65.2 billion in 2010. The substantial growth in net revenue highlights Apple's strong financial performance and market presence in the Tech & Electronics sector during that period.\n"
     ]
    }
   ],
   "source": [
    "# load back the tree by passing it into RetrievalAugmentation\n",
    "\n",
    "RA = RetrievalAugmentation(tree=SAVE_PATH, config=custom_config)\n",
    "\n",
    "question = 'what is apples net revenue in 2012?'\n",
    "\n",
    "answer = RA.answer_question(question=question)\n",
    "print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f0c3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to load JSON file\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Function to save JSON file\n",
    "def save_json(data, filepath):\n",
    "    with open(filepath, 'w') as file:\n",
    "        json.dump(data, file, indent=2)\n",
    "\n",
    "# Function to answer questions using RA model\n",
    "def generate_answers(data, ra_model):\n",
    "    new_data = []\n",
    "    for entry in data:\n",
    "        question = entry[\"question\"]\n",
    "        model_answer = ra_model.answer_question(question=question)\n",
    "        new_entry = {\n",
    "            \"question\": question,\n",
    "            \"answer\": model_answer\n",
    "        }\n",
    "        new_data.append(new_entry)\n",
    "    return new_data\n",
    "\n",
    "# Function to answer questions using RA model\n",
    "def generate_rag_answers(data, ra_model, start_layer):\n",
    "    new_data = []\n",
    "    for entry in data:\n",
    "        question = entry[\"question\"]\n",
    "        model_answer = ra_model.answer_question(question=question,\n",
    "                                                start_layer=start_layer, \n",
    "                                                num_layers=1)\n",
    "        new_entry = {\n",
    "            \"question\": question,\n",
    "            \"answer\": model_answer\n",
    "        }\n",
    "        new_data.append(new_entry)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "132d8cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 22:46:04,718 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 500\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT4oSummarizationModel object at 0x7fba9e8989a0>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fba887ebb20>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2024-06-02 22:46:04,718 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 500\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT4oSummarizationModel object at 0x7fba9e8989a0>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fba887ebb20>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2024-06-02 22:46:04,721 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: OpenAI\n",
      "            Embedding Model: <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fba88808fd0>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "2024-06-02 22:46:04,722 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 500\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT4oSummarizationModel object at 0x7fba9e8989a0>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fba887ebb20>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: OpenAI\n",
      "            Embedding Model: <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fba88808fd0>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <raptor.QAModels.GPT4oQAModel object at 0x7fba9e8983a0>\n",
      "            Tree Builder Type: cluster\n",
      "        \n",
      "2024-06-02 22:46:04,722 - Using collapsed_tree\n",
      "2024-06-02 22:46:05,022 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:10,852 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:10,863 - Using collapsed_tree\n",
      "2024-06-02 22:46:11,041 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:15,039 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:15,045 - Using collapsed_tree\n",
      "2024-06-02 22:46:15,179 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:24,640 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:24,647 - Using collapsed_tree\n",
      "2024-06-02 22:46:24,790 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:28,878 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:28,883 - Using collapsed_tree\n",
      "2024-06-02 22:46:29,037 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:35,199 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:35,205 - Using collapsed_tree\n",
      "2024-06-02 22:46:35,365 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:44,543 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:44,550 - Using collapsed_tree\n",
      "2024-06-02 22:46:44,935 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:52,348 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:46:52,355 - Using collapsed_tree\n",
      "2024-06-02 22:46:52,538 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:06,091 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:06,097 - Using collapsed_tree\n",
      "2024-06-02 22:47:06,253 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:14,342 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:14,351 - Using collapsed_tree\n",
      "2024-06-02 22:47:14,461 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:22,444 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:22,451 - Using collapsed_tree\n",
      "2024-06-02 22:47:22,610 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:28,760 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:28,767 - Using collapsed_tree\n",
      "2024-06-02 22:47:29,963 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:33,366 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:33,373 - Using collapsed_tree\n",
      "2024-06-02 22:47:33,501 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:37,219 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:37,225 - Using collapsed_tree\n",
      "2024-06-02 22:47:37,371 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:42,702 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:42,709 - Using collapsed_tree\n",
      "2024-06-02 22:47:42,904 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:45,786 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:45,791 - Using collapsed_tree\n",
      "2024-06-02 22:47:45,929 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:54,072 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:47:54,079 - Using collapsed_tree\n",
      "2024-06-02 22:47:54,186 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:48:08,103 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:48:08,110 - Using collapsed_tree\n",
      "2024-06-02 22:48:08,264 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:48:11,172 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:48:11,178 - Using collapsed_tree\n",
      "2024-06-02 22:48:11,565 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:48:16,601 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:48:16,606 - Using collapsed_tree\n",
      "2024-06-02 22:48:16,780 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:48:20,697 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:48:20,705 - Using collapsed_tree\n",
      "2024-06-02 22:48:20,800 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:48:43,592 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:48:43,600 - Using collapsed_tree\n",
      "2024-06-02 22:48:43,866 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:48:59,042 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:48:59,049 - Using collapsed_tree\n",
      "2024-06-02 22:48:59,198 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:09,814 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:09,821 - Using collapsed_tree\n",
      "2024-06-02 22:49:10,182 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:17,731 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:17,737 - Using collapsed_tree\n",
      "2024-06-02 22:49:17,887 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:33,762 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:33,769 - Using collapsed_tree\n",
      "2024-06-02 22:49:33,882 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:42,899 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:42,905 - Using collapsed_tree\n",
      "2024-06-02 22:49:43,051 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:47,633 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:47,639 - Using collapsed_tree\n",
      "2024-06-02 22:49:47,777 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:52,855 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:52,861 - Using collapsed_tree\n",
      "2024-06-02 22:49:53,008 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:56,439 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:49:56,446 - Using collapsed_tree\n",
      "2024-06-02 22:49:56,541 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-02 22:50:02,484 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New JSON with model answers saved to evaluations/raptor_output_metadata_3.json\n"
     ]
    }
   ],
   "source": [
    "# Path to your original JSON file\n",
    "json_file_path = 'evaluations/ground_truth_3.json'\n",
    "# Path to save the new JSON file\n",
    "new_json_file_path = 'evaluations/raptor_output_metadata_3.json'\n",
    "\n",
    "# Load the JSON data\n",
    "data = load_json(json_file_path)\n",
    "\n",
    "RA = RetrievalAugmentation(tree=SAVE_PATH, config=custom_config)\n",
    "\n",
    "new_data = generate_answers(data, RA)\n",
    "\n",
    "# Save the new questions and answers to a new JSON file\n",
    "save_json(new_data, new_json_file_path)\n",
    "\n",
    "print(f\"New JSON with model answers saved to {new_json_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d728b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(135):\n",
    "    print('--------------------------------------------')\n",
    "    print(RA.tree.layer_to_nodes[2][i].metadata.company)\n",
    "    print(RA.tree.layer_to_nodes[2][i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb01731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 12:42:46,979 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 500\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT4oSummarizationModel object at 0x7fa2be213940>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fa299af3af0>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2024-06-03 12:42:46,980 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 500\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT4oSummarizationModel object at 0x7fa2be213940>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fa299af3af0>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2024-06-03 12:42:46,985 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: OpenAI\n",
      "            Embedding Model: <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fa299b10fa0>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "2024-06-03 12:42:46,986 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 500\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT4oSummarizationModel object at 0x7fa2be213940>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fa299af3af0>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: OpenAI\n",
      "            Embedding Model: <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7fa299b10fa0>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <raptor.QAModels.GPT4oQAModel object at 0x7fa2be213220>\n",
      "            Tree Builder Type: cluster\n",
      "        \n",
      "2024-06-03 12:42:46,987 - Using collapsed_tree\n",
      "2024-06-03 12:42:47,419 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:42:51,806 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:42:51,816 - Using collapsed_tree\n",
      "2024-06-03 12:42:52,255 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:42:55,840 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:42:55,881 - Using collapsed_tree\n",
      "2024-06-03 12:42:56,199 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:00,722 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:00,729 - Using collapsed_tree\n",
      "2024-06-03 12:43:00,877 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:04,341 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:04,348 - Using collapsed_tree\n",
      "2024-06-03 12:43:04,447 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:14,889 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:14,896 - Using collapsed_tree\n",
      "2024-06-03 12:43:15,055 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:18,892 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:18,899 - Using collapsed_tree\n",
      "2024-06-03 12:43:19,024 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:24,206 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:24,213 - Using collapsed_tree\n",
      "2024-06-03 12:43:24,377 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:28,304 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:28,310 - Using collapsed_tree\n",
      "2024-06-03 12:43:28,471 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:33,318 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:33,324 - Using collapsed_tree\n",
      "2024-06-03 12:43:33,448 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:39,054 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:39,057 - Using collapsed_tree\n",
      "2024-06-03 12:43:39,174 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:44,078 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:44,087 - Using collapsed_tree\n",
      "2024-06-03 12:43:44,176 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:49,674 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:43:49,679 - Using collapsed_tree\n",
      "2024-06-03 12:43:49,829 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:01,786 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:01,791 - Using collapsed_tree\n",
      "2024-06-03 12:44:01,960 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:07,486 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:07,504 - Using collapsed_tree\n",
      "2024-06-03 12:44:07,667 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:11,417 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:11,431 - Using collapsed_tree\n",
      "2024-06-03 12:44:11,731 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:16,639 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:16,645 - Using collapsed_tree\n",
      "2024-06-03 12:44:16,841 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:29,031 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:29,042 - Using collapsed_tree\n",
      "2024-06-03 12:44:29,232 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:35,797 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:35,808 - Using collapsed_tree\n",
      "2024-06-03 12:44:36,012 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:48,173 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:48,180 - Using collapsed_tree\n",
      "2024-06-03 12:44:48,304 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:52,403 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:52,411 - Using collapsed_tree\n",
      "2024-06-03 12:44:52,581 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:44:54,148 - Retrying request to /chat/completions in 0.984054 seconds\n",
      "2024-06-03 12:45:01,565 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:01,572 - Using collapsed_tree\n",
      "2024-06-03 12:45:01,761 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:06,680 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:06,686 - Using collapsed_tree\n",
      "2024-06-03 12:45:06,827 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:11,182 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:11,189 - Using collapsed_tree\n",
      "2024-06-03 12:45:11,301 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:16,003 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:16,009 - Using collapsed_tree\n",
      "2024-06-03 12:45:16,303 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:25,165 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:25,171 - Using collapsed_tree\n",
      "2024-06-03 12:45:25,302 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:31,259 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:31,266 - Using collapsed_tree\n",
      "2024-06-03 12:45:31,436 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:38,933 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:38,941 - Using collapsed_tree\n",
      "2024-06-03 12:45:39,137 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:48,227 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:48,236 - Using collapsed_tree\n",
      "2024-06-03 12:45:48,458 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:51,814 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:51,816 - Using collapsed_tree\n",
      "2024-06-03 12:45:51,910 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-03 12:45:56,954 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New JSON with model answers saved to evaluations/rag0_output_3.json\n"
     ]
    }
   ],
   "source": [
    "# Path to your original JSON file\n",
    "json_file_path = 'evaluations/ground_truth_3.json'\n",
    "# Path to save the new JSON file\n",
    "new_json_file_path = 'evaluations/rag0_output_3.json'\n",
    "\n",
    "# Load the JSON data\n",
    "data = load_json(json_file_path)\n",
    "\n",
    "# Change to only leaf layer\n",
    "RA = RetrievalAugmentation(tree=SAVE_PATH, config=custom_config)\n",
    "\n",
    "new_data = generate_rag_answers(data, RA, start_layer=0)\n",
    "\n",
    "# Save the new questions and answers to a new JSON file\n",
    "save_json(new_data, new_json_file_path)\n",
    "\n",
    "print(f\"New JSON with model answers saved to {new_json_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raptor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
